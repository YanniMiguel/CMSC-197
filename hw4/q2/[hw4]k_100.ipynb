{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d890cc8-4396-4f41-979e-4cdf89600d5f",
   "metadata": {},
   "source": [
    "# CMSC 197 Problem Set 2\n",
    "\n",
    "Adrian Miguel Custodio\n",
    "\n",
    "This notebook filters the top 10k dictionary where words occur more than 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c554bedf-163b-4e4b-8fe3-a993e2cc1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Standard Libraries #####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##### For Preprocessing #####\n",
    "import email  \n",
    "import re \n",
    "from collections import Counter  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae335c-81c2-49f7-b5c4-76747d2dd72d",
   "metadata": {},
   "source": [
    "## Preprocessing of Data\n",
    "\n",
    "Split the dataset into three(3) groups: training set for ham, training set for spam, and the testing\n",
    "set. \n",
    "\n",
    "Remove words from the document which may not contribute to the information we want to\n",
    "extract. These includes dropping the alphanumeric characters and punctuation marks.\n",
    "\n",
    "Also, remove stop words, more popularly known as meaningless words, from the email body\n",
    "since those words are not useful in classification as well as reduce the dimensionality of the\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba0ab2b-9736-423b-8f3e-51481aecbcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/000/000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>data/000/003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label      filepath\n",
       "0         0  data/000/000\n",
       "1         1  data/000/001\n",
       "2         1  data/000/002\n",
       "3         0  data/000/003\n",
       "4         1  data/000/004\n",
       "...     ...           ...\n",
       "37817     1  data/126/017\n",
       "37818     1  data/126/018\n",
       "37819     1  data/126/019\n",
       "37820     1  data/126/020\n",
       "37821     1  data/126/021\n",
       "\n",
       "[37822 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the dataset\n",
    "df_labels = pd.read_csv(\"labels\", sep=\" \")\n",
    "df_labels.columns = [\"label\", \"filepath\"]\n",
    "\n",
    "#change ham labels into 0; spam labels into 1\n",
    "for i, row in df_labels.iterrows():\n",
    "    if df_labels['label'][i] == \"ham\":     \n",
    "        df_labels.at[i,'filepath'] =  (df_labels.at[i,'filepath']).replace(\"../\", \"\")\n",
    "        df_labels.at[i,'label'] = 0\n",
    "    else:\n",
    "        df_labels.at[i,'filepath'] =  (df_labels.at[i,'filepath']).replace(\"../\", \"\")\n",
    "        df_labels.at[i,'label'] = 1\n",
    "        \n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f332436f-c5cb-46d0-8ce0-d788e6f5c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open stop_words file\n",
    "with open(\"stop_words.txt\",\"r\") as file:\n",
    "    stop_words = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d670b7-d240-4cf3-8c1d-47f086b6f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function the cleans the message and rids it of other special characters\n",
    "def message_cleanse(message):\n",
    "    words = \"\"   \n",
    "    \n",
    "    for word in message.split():\n",
    "        #calls function that stores the things to remove\n",
    "        msg = word_cleanup(word)\n",
    "        \n",
    "        #if message is not found in the stop_words file nor is it empty\n",
    "        if msg not in stop_words and msg != \"\" : \n",
    "            words += (msg+\" \")\n",
    "            \n",
    "    return words         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2134fd08-d998-4e66-88fe-7ccf08402247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that stores the characters to be removed from the messages\n",
    "def word_cleanup(msg):\n",
    "    num = \"0123456789\"\n",
    "    html_tags = \"<[^<>]+>\"\n",
    "    \n",
    "    msg = msg.lower()\n",
    "    msg = re.sub(html_tags,'', msg)\n",
    "    msg = re.sub(num,'', msg)\n",
    "    msg = re.sub('[^a-z]','', msg)\n",
    "    \n",
    "    return msg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf046a0-ac68-4d06-8d11-acc9318035b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for checking mulitparts of emails\n",
    "def multipart_checker(message):\n",
    "        msg = \"\"\n",
    "        \n",
    "        #if message is multipart   \n",
    "        if message.is_multipart():\n",
    "            # loops through diff parts of the email\n",
    "            for email_part in message.walk():\n",
    "                # checks content whather if text/plain\n",
    "                if email_part.get_content_type() == \"text/plain\":\n",
    "                    # gets the text/plain part\n",
    "                    msg = email_part.get_payload()  \n",
    "                    break\n",
    "        #not multipart\n",
    "        else:\n",
    "            msg = message.get_payload()\n",
    "        \n",
    "        return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2295a108-e5cf-4082-a9cf-372538aa2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for the email message and its path\n",
    "message_dict = {'filepath':[], 'Message':[]}\n",
    "encode_def = \"ISO-8859-1\" # default encoding\n",
    "\n",
    "#for every path in the dataset\n",
    "for path in df_labels['filepath']:\n",
    "    message_dict['filepath'].append(path)\n",
    "    \n",
    "    # open file for the email content \n",
    "    with open(f\"{path}\", \"r\", encoding = encode_def) as e_mail:\n",
    "        \n",
    "        message = email.message_from_file(e_mail) \n",
    "        \n",
    "        #multipart checker\n",
    "        msg = multipart_checker(message)\n",
    "        #message unusdable characters cleaner\n",
    "        msg_update = message_cleanse(msg)\n",
    "        \n",
    "        # append the cleaned message to the content_dict under content \n",
    "        message_dict['Message'].append(msg_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "222c4370-b757-46db-b287-1a7312f96fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/000/000</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/001</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/002</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>data/000/003</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/004</td>\n",
       "      <td>chauncey conferred luscious continued tonsilli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/017</td>\n",
       "      <td>great news expec ted infinex ventures infx pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/018</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/019</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering pain depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/020</td>\n",
       "      <td>prosperous future increased money earning powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>1</td>\n",
       "      <td>data/126/021</td>\n",
       "      <td>moat coverall cytochemistry planeload salk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37822 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label      filepath                                            Message\n",
       "0         0  data/000/000  mailing list queried weeks ago running set arc...\n",
       "1         1  data/000/001  luxury watches buy rolex rolex cartier bvlgari...\n",
       "2         1  data/000/002  academic qualifications prestigious nonacc red...\n",
       "3         0  data/000/003  greetings verify subscription planfans list ch...\n",
       "4         1  data/000/004  chauncey conferred luscious continued tonsilli...\n",
       "...     ...           ...                                                ...\n",
       "37817     1  data/126/017  great news expec ted infinex ventures infx pri...\n",
       "37818     1  data/126/018  oil sector going crazy weekly gift kkpt thing ...\n",
       "37819     1  data/126/019  httpvdtobjdocscaninfo suffering pain depressio...\n",
       "37820     1  data/126/020  prosperous future increased money earning powe...\n",
       "37821     1  data/126/021        moat coverall cytochemistry planeload salk \n",
       "\n",
       "[37822 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the dictionary into a dataframe and display it with the df_labels data\n",
    "df_content = pd.DataFrame.from_dict(message_dict)\n",
    "df_main= pd.merge(df_labels, df_content, on='filepath')\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b25b354-3825-4d51-a245-676f2dc8b9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000/000</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000/001</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>000/002</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>000/003</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>000/004</td>\n",
       "      <td>chauncey conferred luscious continued tonsilli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21295</th>\n",
       "      <td>1</td>\n",
       "      <td>070/295</td>\n",
       "      <td>btijclnab binpqnejgmb httpgethighbizez bldb xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21296</th>\n",
       "      <td>1</td>\n",
       "      <td>070/296</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21297</th>\n",
       "      <td>1</td>\n",
       "      <td>070/297</td>\n",
       "      <td>doctype html public wcdtd html transitionalen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21298</th>\n",
       "      <td>0</td>\n",
       "      <td>070/298</td>\n",
       "      <td>mounted isu infrared demodulator hb realised r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21299</th>\n",
       "      <td>1</td>\n",
       "      <td>070/299</td>\n",
       "      <td>httptmqmctoverpacenet suffering pain depressio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label filepath                                            Message\n",
       "0         0  000/000  mailing list queried weeks ago running set arc...\n",
       "1         1  000/001  luxury watches buy rolex rolex cartier bvlgari...\n",
       "2         1  000/002  academic qualifications prestigious nonacc red...\n",
       "3         0  000/003  greetings verify subscription planfans list ch...\n",
       "4         1  000/004  chauncey conferred luscious continued tonsilli...\n",
       "...     ...      ...                                                ...\n",
       "21295     1  070/295  btijclnab binpqnejgmb httpgethighbizez bldb xi...\n",
       "21296     1  070/296  special offer adobe video collection adobe pre...\n",
       "21297     1  070/297  doctype html public wcdtd html transitionalen ...\n",
       "21298     0  070/298  mounted isu infrared demodulator hb realised r...\n",
       "21299     1  070/299  httptmqmctoverpacenet suffering pain depressio...\n",
       "\n",
       "[21300 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removes the \"data/\" part of path to use the files numerically\n",
    "for i, row in df_main.iterrows():\n",
    "    df_main.at[i,'filepath'] =  (df_main.at[i,'filepath']).replace(\"data/\", \"\")\n",
    "\n",
    "#training data set\n",
    "df_train = df_main[df_main['filepath']<= '071']\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9755f76b-a3f8-4c14-b62f-45c670288918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000/000</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>000/003</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>000/005</td>\n",
       "      <td>quiet quiet well straw poll plan running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>000/006</td>\n",
       "      <td>working departed totally bell labs recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>000/010</td>\n",
       "      <td>greetings mass acknowledgement signed planfans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>21270</td>\n",
       "      <td>0</td>\n",
       "      <td>070/270</td>\n",
       "      <td>equation generate prime numbers equation theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>21271</td>\n",
       "      <td>0</td>\n",
       "      <td>070/271</td>\n",
       "      <td>equation generate prime numbers equation theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>21288</td>\n",
       "      <td>0</td>\n",
       "      <td>070/288</td>\n",
       "      <td>dear dmdx users guidance generating dmdx item ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>21293</td>\n",
       "      <td>0</td>\n",
       "      <td>070/293</td>\n",
       "      <td>built handyboard works great testmotor passes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>21298</td>\n",
       "      <td>0</td>\n",
       "      <td>070/298</td>\n",
       "      <td>mounted isu infrared demodulator hb realised r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7523 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index label filepath                                            Message\n",
       "0         0     0  000/000  mailing list queried weeks ago running set arc...\n",
       "1         3     0  000/003  greetings verify subscription planfans list ch...\n",
       "2         5     0  000/005          quiet quiet well straw poll plan running \n",
       "3         6     0  000/006  working departed totally bell labs recommended...\n",
       "4        10     0  000/010  greetings mass acknowledgement signed planfans...\n",
       "...     ...   ...      ...                                                ...\n",
       "7518  21270     0  070/270  equation generate prime numbers equation theor...\n",
       "7519  21271     0  070/271  equation generate prime numbers equation theor...\n",
       "7520  21288     0  070/288  dear dmdx users guidance generating dmdx item ...\n",
       "7521  21293     0  070/293  built handyboard works great testmotor passes ...\n",
       "7522  21298     0  070/298  mounted isu infrared demodulator hb realised r...\n",
       "\n",
       "[7523 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data set of ham\n",
    "ham_train_set = df_train[df_train['label'] == 0]\n",
    "ham_train_set.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff12614-71e2-4729-bc3a-f0bcbb46a76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>000/001</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>000/002</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>000/004</td>\n",
       "      <td>chauncey conferred luscious continued tonsilli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>000/007</td>\n",
       "      <td>nbc today body diet beaches magazines hollywoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>000/008</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13772</th>\n",
       "      <td>21294</td>\n",
       "      <td>1</td>\n",
       "      <td>070/294</td>\n",
       "      <td>txtadd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13773</th>\n",
       "      <td>21295</td>\n",
       "      <td>1</td>\n",
       "      <td>070/295</td>\n",
       "      <td>btijclnab binpqnejgmb httpgethighbizez bldb xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>21296</td>\n",
       "      <td>1</td>\n",
       "      <td>070/296</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13775</th>\n",
       "      <td>21297</td>\n",
       "      <td>1</td>\n",
       "      <td>070/297</td>\n",
       "      <td>doctype html public wcdtd html transitionalen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13776</th>\n",
       "      <td>21299</td>\n",
       "      <td>1</td>\n",
       "      <td>070/299</td>\n",
       "      <td>httptmqmctoverpacenet suffering pain depressio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13777 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index label filepath                                            Message\n",
       "0          1     1  000/001  luxury watches buy rolex rolex cartier bvlgari...\n",
       "1          2     1  000/002  academic qualifications prestigious nonacc red...\n",
       "2          4     1  000/004  chauncey conferred luscious continued tonsilli...\n",
       "3          7     1  000/007  nbc today body diet beaches magazines hollywoo...\n",
       "4          8     1  000/008  oil sector going crazy weekly gift kkpt thing ...\n",
       "...      ...   ...      ...                                                ...\n",
       "13772  21294     1  070/294                                            txtadd \n",
       "13773  21295     1  070/295  btijclnab binpqnejgmb httpgethighbizez bldb xi...\n",
       "13774  21296     1  070/296  special offer adobe video collection adobe pre...\n",
       "13775  21297     1  070/297  doctype html public wcdtd html transitionalen ...\n",
       "13776  21299     1  070/299  httptmqmctoverpacenet suffering pain depressio...\n",
       "\n",
       "[13777 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training dataset of spam\n",
    "spam_train_set = df_train[df_train['label'] == 1]\n",
    "spam_train_set.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049c9334-2990-4d14-b66c-3bc28a67ab63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21300</td>\n",
       "      <td>1</td>\n",
       "      <td>071/000</td>\n",
       "      <td>hesitantly derive perverse satisfaction clodho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21301</td>\n",
       "      <td>0</td>\n",
       "      <td>071/001</td>\n",
       "      <td>things perform experiment display will remain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21302</td>\n",
       "      <td>1</td>\n",
       "      <td>071/002</td>\n",
       "      <td>best offer month viggra ci ialis vaiium xa naa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21303</td>\n",
       "      <td>1</td>\n",
       "      <td>071/003</td>\n",
       "      <td>de ar wne cr doesnt matter ow real st mmed ia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21304</td>\n",
       "      <td>1</td>\n",
       "      <td>071/004</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16517</th>\n",
       "      <td>37817</td>\n",
       "      <td>1</td>\n",
       "      <td>126/017</td>\n",
       "      <td>great news expec ted infinex ventures infx pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16518</th>\n",
       "      <td>37818</td>\n",
       "      <td>1</td>\n",
       "      <td>126/018</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16519</th>\n",
       "      <td>37819</td>\n",
       "      <td>1</td>\n",
       "      <td>126/019</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering pain depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16520</th>\n",
       "      <td>37820</td>\n",
       "      <td>1</td>\n",
       "      <td>126/020</td>\n",
       "      <td>prosperous future increased money earning powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16521</th>\n",
       "      <td>37821</td>\n",
       "      <td>1</td>\n",
       "      <td>126/021</td>\n",
       "      <td>moat coverall cytochemistry planeload salk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index label filepath                                            Message\n",
       "0      21300     1  071/000  hesitantly derive perverse satisfaction clodho...\n",
       "1      21301     0  071/001  things perform experiment display will remain ...\n",
       "2      21302     1  071/002  best offer month viggra ci ialis vaiium xa naa...\n",
       "3      21303     1  071/003  de ar wne cr doesnt matter ow real st mmed ia ...\n",
       "4      21304     1  071/004  special offer adobe video collection adobe pre...\n",
       "...      ...   ...      ...                                                ...\n",
       "16517  37817     1  126/017  great news expec ted infinex ventures infx pri...\n",
       "16518  37818     1  126/018  oil sector going crazy weekly gift kkpt thing ...\n",
       "16519  37819     1  126/019  httpvdtobjdocscaninfo suffering pain depressio...\n",
       "16520  37820     1  126/020  prosperous future increased money earning powe...\n",
       "16521  37821     1  126/021        moat coverall cytochemistry planeload salk \n",
       "\n",
       "[16522 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing dataset\n",
    "df_test = df_main[df_main['filepath'] > '071']\n",
    "df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d7a7d7d-f7f8-4c7e-9928-69512dc70400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dict where K = 100:  2848\n"
     ]
    }
   ],
   "source": [
    "#top \n",
    "dict_top_10k = {}\n",
    "\n",
    "for i, r in df_train.iterrows():\n",
    "    for word in str(r['Message']).split():\n",
    "        if word in dict_top_10k:\n",
    "            dict_top_10k[word] += 1\n",
    "        else:\n",
    "            dict_top_10k[word] = 1\n",
    "\n",
    "#sort the dictionary to be from most frequent to least\n",
    "dict_sort = sorted(dict_top_10k.items(), key=lambda x: x[1], reverse=True)\n",
    "dict_sort = dict(dict_sort)\n",
    "top_10k_words= {i : j for i, j in dict_sort.items() if j > 100}\n",
    "\n",
    "print(\"Length of Dict where K = 100: \", len(top_10k_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ba5ed-b74a-4f52-9e2e-d1e43977e60b",
   "metadata": {},
   "source": [
    "# Creating the Feature Matrices\n",
    "\n",
    "Create feature matrices for both the spam training set and ham training set with a dimensionality of 2848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f593a345-8c69-4c91-92f1-39268dc5754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting the dictionary into a list for index purposes\n",
    "top_10k_words_list = list(top_10k_words.keys())\n",
    "\n",
    "#matrix of zeros all 10k words for the ham train set\n",
    "ham_feat_matrix= np.zeros((len(ham_train_set), 2848))\n",
    "\n",
    "#for loop to iterate through the ham training set to update the matrix\n",
    "for i in range(len(ham_train_set)):\n",
    "    for word in str(ham_train_set.iloc[i]['Message']).split():\n",
    "        #checks if the word encountered is in the 10k words\n",
    "        if word in top_10k_words:\n",
    "            ham_feat_matrix[i][top_10k_words_list.index(word)] = 1\n",
    "ham_feat_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f6ed2e8-4b6c-418a-a589-7b0d89b6a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bb</th>\n",
       "      <th>td</th>\n",
       "      <th>will</th>\n",
       "      <th>width</th>\n",
       "      <th>board</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>company</th>\n",
       "      <th>gold</th>\n",
       "      <th>email</th>\n",
       "      <th>...</th>\n",
       "      <th>objects</th>\n",
       "      <th>xc</th>\n",
       "      <th>audio</th>\n",
       "      <th>uf</th>\n",
       "      <th>formal</th>\n",
       "      <th>micro</th>\n",
       "      <th>iaa</th>\n",
       "      <th>cycle</th>\n",
       "      <th>affect</th>\n",
       "      <th>leg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7523 rows × 2848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bb   td  will  width  board  size  price  company  gold  email  ...  \\\n",
       "0     0.0  0.0   1.0    0.0    0.0   0.0    0.0      0.0   0.0    1.0  ...   \n",
       "1     0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "2     0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "3     0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "4     0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "...   ...  ...   ...    ...    ...   ...    ...      ...   ...    ...  ...   \n",
       "7518  0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    1.0  ...   \n",
       "7519  0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    1.0  ...   \n",
       "7520  0.0  0.0   1.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "7521  0.0  0.0   1.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "7522  0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "\n",
       "      objects   xc  audio   uf  formal  micro  iaa  cycle  affect  leg  \n",
       "0         0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "1         0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "2         0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "3         0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "4         0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "...       ...  ...    ...  ...     ...    ...  ...    ...     ...  ...  \n",
       "7518      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "7519      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "7520      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "7521      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "7522      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "\n",
       "[7523 rows x 2848 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data frame version of the matrix\n",
    "ham_df = pd.DataFrame(ham_feat_matrix, columns = top_10k_words)\n",
    "ham_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a9e524-7f9e-48b6-ba7d-ec56f2f3e984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix of zeros for all 10k words for the ham train set\n",
    "spam_feat_matrix = np.zeros((len(spam_train_set), 2848))\n",
    "\n",
    "#for loop to iterate through the spam training set to update the matrix\n",
    "for i in range(len(spam_train_set)):\n",
    "    for word in str(spam_train_set.iloc[i]['Message']).split():\n",
    "        #checks if the word encountered is in the 10k words\n",
    "        if word in top_10k_words:\n",
    "            spam_feat_matrix[i][top_10k_words_list.index(word)] = 1\n",
    "\n",
    "spam_feat_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db1022f-3122-4d42-b1d9-424b0e0e76fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bb</th>\n",
       "      <th>td</th>\n",
       "      <th>will</th>\n",
       "      <th>width</th>\n",
       "      <th>board</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>company</th>\n",
       "      <th>gold</th>\n",
       "      <th>email</th>\n",
       "      <th>...</th>\n",
       "      <th>objects</th>\n",
       "      <th>xc</th>\n",
       "      <th>audio</th>\n",
       "      <th>uf</th>\n",
       "      <th>formal</th>\n",
       "      <th>micro</th>\n",
       "      <th>iaa</th>\n",
       "      <th>cycle</th>\n",
       "      <th>affect</th>\n",
       "      <th>leg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13777 rows × 2848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bb   td  will  width  board  size  price  company  gold  email  ...  \\\n",
       "0      0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   1.0    0.0  ...   \n",
       "1      0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "2      0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "3      0.0  0.0   1.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "4      0.0  0.0   1.0    0.0    0.0   0.0    1.0      0.0   0.0    0.0  ...   \n",
       "...    ...  ...   ...    ...    ...   ...    ...      ...   ...    ...  ...   \n",
       "13772  0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "13773  0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "13774  0.0  0.0   0.0    0.0    0.0   0.0    1.0      0.0   0.0    0.0  ...   \n",
       "13775  0.0  0.0   0.0    1.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "13776  0.0  0.0   0.0    0.0    0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "\n",
       "       objects   xc  audio   uf  formal  micro  iaa  cycle  affect  leg  \n",
       "0          0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "1          0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "2          0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "3          0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "4          0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "...        ...  ...    ...  ...     ...    ...  ...    ...     ...  ...  \n",
       "13772      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "13773      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "13774      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "13775      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "13776      0.0  0.0    0.0  0.0     0.0    0.0  0.0    0.0     0.0  0.0  \n",
       "\n",
       "[13777 rows x 2848 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data frame version of the matrix\n",
    "spam_df = pd.DataFrame(spam_feat_matrix, columns = top_10k_words)\n",
    "spam_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb9785-dbfa-4850-9757-130c7cd47913",
   "metadata": {},
   "source": [
    "# Computing the Priors\n",
    "\n",
    "Prior probabilities of Ham and Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "231da527-c6fa-4316-9228-d9372e2425a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3531924882629108"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P (c=ham) = number of ham emails in train set/overall email train set size\n",
    "prob_ham = ham_train_set.count(axis=0)[0] / df_train.shape[0]  \n",
    "prob_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a3fac6b-06f7-4544-98d5-baf74f2cc881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6468075117370892"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P (c=ham) = number of ham emails in train set/overall email train set size\n",
    "prob_spam = spam_train_set.count(axis=0)[0] / df_train.shape[0]  \n",
    "prob_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c2bad-8012-40bd-aaa9-c1a0b8e5d936",
   "metadata": {},
   "source": [
    "# Computing the Likelihood of each word (+ Laplace Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5ede6e4-8960-4c7e-9c45-4250c87b42ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham Word Proabilities:  [6.56096227e-05 5.10297066e-05 8.40167669e-03 ... 2.18698742e-04\n",
      " 2.11408784e-04 1.82248952e-04]\n",
      "Spam Word Proabilities:  [3.21091079e-03 2.16058339e-03 6.94856234e-03 ... 3.15413633e-06\n",
      " 5.36203177e-05 9.46240900e-06]\n"
     ]
    }
   ],
   "source": [
    "#function for laplace smoothing\n",
    "# equation of probability: (word count + alpha) / (total words + alpha * number of words in vocabulary) \n",
    "def laplace_smoothing(feature_matrix,top_10k_words, alpha):\n",
    "        #sets an array of zeros\n",
    "        p_count = np.zeros(len(top_10k_words))\n",
    "        #calculates word count\n",
    "        word_count = np.sum(feature_matrix, axis= 0)\n",
    "        #counts the amount of words in the data sets\n",
    "        total_words = np.sum (word_count)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #length of the top 10k words dataset\n",
    "        top_word_len = len(top_10k_words)\n",
    "        \n",
    "        #using the equation, calculates the probability of words whether it be ham or spam\n",
    "        for i in range (top_word_len):\n",
    "            curr_data = (word_count[i] + alpha) / (total_words + alpha*top_word_len)\n",
    "            p_count[i] = curr_data\n",
    "        return p_count\n",
    "    \n",
    "alpha = 1\n",
    "    \n",
    "ham_word_p = laplace_smoothing(ham_feat_matrix, top_10k_words, alpha)\n",
    "print(\"Ham Word Proabilities: \",ham_word_p)\n",
    "\n",
    "spam_word_p = laplace_smoothing(spam_feat_matrix, top_10k_words, alpha)\n",
    "print(\"Spam Word Proabilities: \",spam_word_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846ff28-b772-4847-a1e3-100514e6a5cf",
   "metadata": {},
   "source": [
    "# Classify Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94601925-33d9-453b-a33d-0f7fbf22a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for classifying emails\n",
    "def email_checker (email, prob_ham, prob_spam, ham_word_p, spam_word_p, words_list):\n",
    "    #initialize variables\n",
    "    ham_log = 0\n",
    "    spam_log = 0\n",
    "    \n",
    "    #add the initial log probabilities of ham and spam\n",
    "    ham_log = ham_log + np.log(prob_ham)\n",
    "    spam_log = spam_log + np.log(prob_spam)\n",
    "    \n",
    "    \n",
    "    #email message split into strings to be tokenized\n",
    "    sentence = str(email).split()\n",
    "    \n",
    "    #for every word in the message\n",
    "    for word in sentence:\n",
    "        #if word is in the top 10k words, the probabilities for both ham and spam gets higher\n",
    "        if word in top_10k_words:\n",
    "            ham_log =  ham_log + np.log(ham_word_p[words_list.index(word)])\n",
    "            spam_log = spam_log + np.log(spam_word_p[words_list.index(word)])\n",
    "    \n",
    "    #return 0 if email is more likely to be ham, else return 1 for spam\n",
    "    if ham_log > spam_log:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3adb4-ebb9-4fea-ace9-3444fce08660",
   "metadata": {},
   "source": [
    "# Testing the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad6cd3ec-d124-4a37-8e5b-105aa4c5dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\airco\\AppData\\Local\\Temp\\ipykernel_16804\\763495712.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predicted'] = df_test['Message'].apply(lambda msg: email_checker(msg, prob_ham, prob_spam, ham_word_p, spam_word_p , top_10k_words_list))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>Message</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>1</td>\n",
       "      <td>071/000</td>\n",
       "      <td>hesitantly derive perverse satisfaction clodho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>0</td>\n",
       "      <td>071/001</td>\n",
       "      <td>things perform experiment display will remain ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>1</td>\n",
       "      <td>071/002</td>\n",
       "      <td>best offer month viggra ci ialis vaiium xa naa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>1</td>\n",
       "      <td>071/003</td>\n",
       "      <td>de ar wne cr doesnt matter ow real st mmed ia ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>1</td>\n",
       "      <td>071/004</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>1</td>\n",
       "      <td>126/017</td>\n",
       "      <td>great news expec ted infinex ventures infx pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>1</td>\n",
       "      <td>126/018</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>1</td>\n",
       "      <td>126/019</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering pain depressio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>1</td>\n",
       "      <td>126/020</td>\n",
       "      <td>prosperous future increased money earning powe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>1</td>\n",
       "      <td>126/021</td>\n",
       "      <td>moat coverall cytochemistry planeload salk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label filepath                                            Message  \\\n",
       "21300     1  071/000  hesitantly derive perverse satisfaction clodho...   \n",
       "21301     0  071/001  things perform experiment display will remain ...   \n",
       "21302     1  071/002  best offer month viggra ci ialis vaiium xa naa...   \n",
       "21303     1  071/003  de ar wne cr doesnt matter ow real st mmed ia ...   \n",
       "21304     1  071/004  special offer adobe video collection adobe pre...   \n",
       "...     ...      ...                                                ...   \n",
       "37817     1  126/017  great news expec ted infinex ventures infx pri...   \n",
       "37818     1  126/018  oil sector going crazy weekly gift kkpt thing ...   \n",
       "37819     1  126/019  httpvdtobjdocscaninfo suffering pain depressio...   \n",
       "37820     1  126/020  prosperous future increased money earning powe...   \n",
       "37821     1  126/021        moat coverall cytochemistry planeload salk    \n",
       "\n",
       "       predicted  \n",
       "21300          1  \n",
       "21301          0  \n",
       "21302          1  \n",
       "21303          1  \n",
       "21304          1  \n",
       "...          ...  \n",
       "37817          1  \n",
       "37818          1  \n",
       "37819          1  \n",
       "37820          1  \n",
       "37821          1  \n",
       "\n",
       "[16522 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the test dataset to, uh, test the email checker/classifier\n",
    "df_test['predicted'] = df_test['Message'].apply(lambda msg: email_checker(msg, prob_ham, prob_spam, ham_word_p, spam_word_p , top_10k_words_list))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412b304-7f42-4cac-b86f-15e03b55b702",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271806ae-2675-4f5b-89c5-de7c60aefced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Act Val</th>\n",
       "      <th>Pred Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>071/000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>071/001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>071/002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>071/003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>071/004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>126/017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>126/018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>126/019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>126/020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>126/021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16522 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Filepath  Act Val  Pred Val\n",
       "21300  071/000        1         1\n",
       "21301  071/001        0         0\n",
       "21302  071/002        1         1\n",
       "21303  071/003        1         1\n",
       "21304  071/004        1         1\n",
       "...        ...      ...       ...\n",
       "37817  126/017        1         1\n",
       "37818  126/018        1         1\n",
       "37819  126/019        1         1\n",
       "37820  126/020        1         1\n",
       "37821  126/021        1         1\n",
       "\n",
       "[16522 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn the categories into array to ensure they are of the same type and display results\n",
    "actual = np.array(df_test['label']).tolist()\n",
    "prediction = np.array(df_test['predicted']).tolist()\n",
    "\n",
    "comparisons_df = pd.DataFrame({\"Filepath\":df_test['filepath'],\"Act Val\": actual, \"Pred Val\": prediction})\n",
    "comparisons_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec2322d2-bfc2-4318-8bea-708db4f586da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score= 0.9306379372957269\n",
      "Recall Score = 0.9259991019308487\n",
      "Precision Score = 0.9697169190256748\n"
     ]
    }
   ],
   "source": [
    "#utilizing sklearns' accuracy, recall, and precision functions to check their scores\n",
    "print(f\"Accuracy Score= {accuracy_score(actual,prediction)}\")\n",
    "print(f\"Recall Score = {recall_score(actual,prediction)}\")\n",
    "print(f\"Precision Score = {precision_score(actual,prediction)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
